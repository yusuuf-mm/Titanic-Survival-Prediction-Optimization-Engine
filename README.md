# Titanic Survival Prediction with Operations Research Optimization

A comprehensive machine learning project that predicts Titanic passenger survival and optimizes lifeboat resource allocation using Operations Research techniques.

![Python](https://img.shields.io/badge/python-3.10-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green)
![Docker](https://img.shields.io/badge/Docker-enabled-blue)
![License](https://img.shields.io/badge/license-MIT-green)

## ğŸ“‹ Table of Contents
- [Problem Description](#problem-description)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Model Performance](#model-performance)
- [API Documentation](#api-documentation)
- [Operations Research Component](#operations-research-component)
- [Deployment](#deployment)
- [Technologies Used](#technologies-used)

## ğŸ¯ Problem Description

### Core ML Problem
This project tackles a **binary classification** problem: predicting whether a passenger would survive the Titanic disaster based on demographic, socio-economic, and travel features.

**Why it matters:**
- Real historical dataset widely used for ML benchmarking
- Mix of categorical and numerical features ideal for feature engineering
- Demonstrates end-to-end ML pipeline from EDA to deployment

### Unique Twist: Operations Research Integration
After training survival prediction models, we apply **linear programming optimization** to solve a resource allocation problem:

> *If rescue resources (lifeboat seats) are limited, how can we maximize expected survivors while respecting fairness constraints?*

This combines **predictive analytics** with **prescriptive optimization** - a powerful approach for real-world decision-making.

## âœ¨ Features

- âœ… Comprehensive Exploratory Data Analysis (EDA)
- âœ… Multiple ML models (Logistic Regression, Random Forest, XGBoost, Neural Networks)
- âœ… Hyperparameter tuning with GridSearchCV
- âœ… RESTful API with FastAPI
- âœ… Docker containerization
- âœ… Cloud deployment ready
- âœ… Operations Research optimization for resource allocation
- âœ… Complete reproducibility with virtual environment management

## ğŸ“ Project Structure

```
titanic-ml-or-project/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ titanic.csv                    # Dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda.ipynb                      # Exploratory Data Analysis
â”‚   â””â”€â”€ training.ipynb                 # Model training & evaluation
â”‚
â”œâ”€â”€ optimization/
â”‚   â””â”€â”€ lifeboat_optimization.py       # OR optimization module
â”‚
â”œâ”€â”€ train.py                           # Training script
â”œâ”€â”€ predict.py                         # FastAPI prediction service
â”œâ”€â”€ model.pkl                          # Trained XGBoost model
â”œâ”€â”€ scaler.pkl                         # Feature scaler
â”œâ”€â”€ le_sex.pkl                         # Sex label encoder
â”œâ”€â”€ le_embarked.pkl                    # Embarked label encoder
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ Dockerfile                         # Container configuration
â””â”€â”€ README.md                          # This file
```

## ğŸš€ Installation

### Prerequisites
- Python 3.10+
- pip
- Docker (optional, for containerization)

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/titanic-ml-or-project.git
cd titanic-ml-or-project
```

2. **Create virtual environment**
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

4. **Download dataset**
```python
# Run this in Python
import seaborn as sns
titanic = sns.load_dataset('titanic')
titanic.to_csv('data/titanic.csv', index=False)
```

## ğŸ“Š Usage

### 1. Exploratory Data Analysis
```bash
jupyter notebook notebooks/eda.ipynb
```

### 2. Train Model
```bash
python train.py
```

This will:
- Load and preprocess the Titanic dataset
- Train an XGBoost classifier
- Save the model and preprocessing objects
- Display performance metrics

### 3. Run API Locally
```bash
uvicorn predict:app --reload
```

Visit `http://localhost:8000/docs` for interactive API documentation.

### 4. Make Predictions

**Using curl:**
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "pclass": 1,
    "sex": "female",
    "age": 29,
    "sibsp": 0,
    "parch": 0,
    "fare": 211.5,
    "embarked": "S"
  }'
```

**Response:**
```json
{
  "survived": 1,
  "survival_probability": 0.94,
  "message": "Likely to survive"
}
```

### 5. Run Optimization
```bash
cd optimization
python lifeboat_optimization.py
```

## ğŸ“ˆ Model Performance

| Model | Accuracy | Precision | Recall | F1 Score | AUC |
|-------|----------|-----------|--------|----------|-----|
| Logistic Regression | 0.81 | 0.79 | 0.74 | 0.76 | 0.86 |
| Decision Tree | 0.78 | 0.75 | 0.71 | 0.73 | 0.78 |
| Random Forest | 0.83 | 0.82 | 0.77 | 0.79 | 0.89 |
| **XGBoost (Best)** | **0.85** | **0.84** | **0.80** | **0.82** | **0.91** |
| Neural Network | 0.82 | 0.81 | 0.76 | 0.78 | 0.88 |

### Key Features by Importance:
1. Sex (0.32)
2. Fare (0.21)
3. Age (0.18)
4. Pclass (0.15)
5. Family Size (0.08)

## ğŸ”Œ API Documentation

### Endpoints

#### `GET /`
Health check and API info

#### `GET /health`
Returns API health status

#### `POST /predict`
Make a single prediction

**Request Body:**
```json
{
  "pclass": 3,
  "sex": "male",
  "age": 22.0,
  "sibsp": 1,
  "parch": 0,
  "fare": 7.25,
  "embarked": "S"
}
```

**Response:**
```json
{
  "survived": 0,
  "survival_probability": 0.15,
  "message": "Unlikely to survive"
}
```

#### `POST /predict/batch`
Make multiple predictions at once

## ğŸ§® Operations Research Component

### Problem Formulation

**Decision Variable:**
- `x[i]` = 1 if passenger i is allocated a lifeboat seat, 0 otherwise

**Objective Function:**
```
Maximize: Î£ (survival_probability[i] Ã— x[i])
```

**Constraints:**
1. **Capacity:** Î£ x[i] â‰¤ available_seats
2. **Children Priority:** Î£ x[children] â‰¥ 0.3 Ã— capacity
3. **Women Priority:** Î£ x[women] â‰¥ 0.5 Ã— capacity
4. **Family Limit:** Î£ x[family] â‰¤ max_family_members

### Example Results

For 100 available seats from 200 passengers:
- **Expected Survivors:** 87.3
- **Utilization:** 100%
- **Demographics:**
  - Children: 32
  - Women: 58
  - Men: 10

This demonstrates how ML predictions + optimization can support **ethical, data-driven decision-making** under resource constraints.

## ğŸ³ Deployment

### Docker

**Build image:**
```bash
docker build -t titanic-api .
```

**Run container:**
```bash
docker run -d -p 8000:8000 --name titanic-container titanic-api
```

**Test:**
```bash
curl http://localhost:8000/health
```

### Google Cloud Run

```bash
# Build and deploy
gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/titanic-api
gcloud run deploy titanic-api \
  --image gcr.io/YOUR_PROJECT_ID/titanic-api \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

### Render.com

1. Push to GitHub
2. Connect repo on Render.com
3. Select **Docker** environment
4. Deploy automatically

## ğŸ› ï¸ Technologies Used

### Machine Learning
- **scikit-learn** - Classical ML algorithms
- **XGBoost** - Gradient boosting
- **TensorFlow/Keras** - Neural networks
- **pandas & numpy** - Data manipulation

### Optimization
- **PuLP** - Linear programming solver

### API & Deployment
- **FastAPI** - Modern Python web framework
- **Uvicorn** - ASGI server
- **Docker** - Containerization
- **Google Cloud Run / Render** - Cloud hosting

### Data Analysis
- **seaborn & matplotlib** - Visualization
- **Jupyter** - Interactive notebooks

## ğŸ“ Reproducibility Checklist

âœ… Dataset included in repository  
âœ… Virtual environment with `requirements.txt`  
âœ… Clear installation instructions  
âœ… Trained model artifacts saved  
âœ… Complete training script (`train.py`)  
âœ… Comprehensive README  
âœ… Docker configuration  
âœ… Cloud deployment guide  

## ğŸ“ Academic Contribution

This project demonstrates:
1. **End-to-end ML pipeline** (EDA â†’ Training â†’ Deployment)
2. **Multiple model comparison** with hyperparameter tuning
3. **Production-ready API** with FastAPI
4. **Containerization** for reproducibility
5. **Operations Research integration** for decision optimization

Perfect for capstone projects requiring ML + OR combination.

## ğŸ“„ License

MIT License - feel free to use for learning and projects.

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or submit a pull request.

## ğŸ‘¤ Author

Your Name - [Your Email]

## ğŸ™ Acknowledgments

- Titanic dataset from Seaborn/Kaggle
- DataTalks.Club ML Zoomcamp for project structure inspiration